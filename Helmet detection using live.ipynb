{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #immporting OpenCV, numpy and time\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "net = cv2.dnn.readNet('yolov4-obj_1000.weights','yolov4-obj.cfg') #loading trained weight file and cfg file for helmet class.\n",
    "\n",
    "classes = ['Helmet'] #because I am working on one class only\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0) #using camera for detection\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_DUPLEX \n",
    "starting_time = time.time() \n",
    "frame_id = 0 \n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, img = cap.read() #capturing frame from a live video and converting it into image and reading it\n",
    "    height, width, _ = img.shape #getting shape of the image\n",
    "    frame_id += 1   \n",
    "    #now for yolo we have to resize the image in a square that fits the size for yolov3 or yolov4\n",
    "    #also we need to normalize it by dividing the pixel value by 255 and the valued are also need to be in RGB order (it is in BGR so we need to swapping).\n",
    "    #so for that preparing image called blob       \n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB = True, crop = False)\n",
    "    #showing what we have done using blob from image\n",
    "    #for b in blob:\n",
    "    #   for n, img_blob in enumerate(b):\n",
    "    #   cv2.imshow(str(n),img_blob)#this is showing our input image after the mean substraction normalizing and also the channel swapping \n",
    "    #so as in the output we can see the red channel, green channel and also the blue channel\n",
    "    #this blob function is used to create for input image and to use it as an input to our models \n",
    "    #and taking blob image in input\n",
    "    net.setInput(blob)\n",
    "    #now we want to know bonding boxes or predicted classes and also need to get the output layera names and then pass the name into the forward function\n",
    "    #creating for getting the output layer name first\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layersOutputs = net.forward(output_layers_names)\n",
    "     #we are not ready yet, we need to extract the bounding boxes and the confidences and the predicted classes which will be started in two different lists\n",
    "     #1st for boxes, 2nd for confidences and other also for \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    #creating bounding boxes\n",
    "    for output in layersOutputs:   \n",
    "        for detection in output:   #for extracting the information from each of the output\n",
    "            scores = detection[5:]  #started for 6 , all the 18 classes predictions\n",
    "            class_id = np.argmax(scores)  #extracting highest scores\n",
    "            confidence = scores[class_id]  #for finding the maximum value from these class\n",
    "            # a confidence that is high enough for us to consider that the object is being detected        \n",
    "\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0]*width) #under the detection all it is normalized\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h]) #appending the boxes in thel ist and also 4 coordinates is here bcz it's a rectangular shape\n",
    "                class_ids.append(class_id)\n",
    "                confidences.append((float(confidence)))\n",
    "\n",
    "    #print(len(boxes))\n",
    "    #print(detection)\n",
    "#now we will get multiple box for a single object so to only keep the higher scores we will use non maximum supressions \n",
    "#in a argument we will use boxes that we have got, the confiden\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    #print(indexes.flatten())\n",
    "    #print(type(indexes))\n",
    "        \n",
    "    colors = np.random.uniform(0, 255, size = (len(boxes), 3)) \n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y , w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), color, 8)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 1,(255,255,255) , 2)\n",
    "\n",
    "    elapsed_time = time.time() - starting_time\n",
    "    fps = frame_id / elapsed_time\n",
    "    cv2.putText(img, \"FPS: \" + str(fps), (10,30), font, 1, (0,0,0), 1)\n",
    "    cv2.imshow('Output',cv2.resize(img,(700, 500)))  \n",
    "    cv2.resize(img,(600, 400))\n",
    "    key = cv2.waitKey(1)  #0\n",
    "        \n",
    "    #if the 'c' key is pressed, stop the loop\n",
    "    if key == ord('c'):\n",
    "       break    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
